{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x105ea1c00>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "\n",
    "from sae_lens import SparseAutoencoder\n",
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "\n",
    "from steering.eval_utils import evaluate_completions\n",
    "from steering.utils import get_activation_steering, get_sae_diff_steering, remove_sae_feats, text_to_sae_feats, top_activations\n",
    "from steering.patch import generate, get_loss\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slava/safety/steering/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "hp_6 = tutils.get_act_name(\"resid_pre\", 6)\n",
    "sae_6 = get_gpt2_res_jb_saes(hp_6)[0][hp_6]\n",
    "sae_6 = sae_6.to(model.W_E.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering = get_activation_steering(model, hp_6, pos_text=\"Anger\", neg_text=\"Calm\")\n",
    "steering = steering[0, -1, :]\n",
    "steering = steering.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I think I have funded myself in all these unique ways in my life.\\n\\nHow it impacts people is',\n",
       " \"I think he was very angry. He said, 'the Statue of the American flag is more of the symbol\",\n",
       " \"I think the issue doesn't even need to be two sides and arguments, even if it gets through to them\",\n",
       " 'I think some (preemption is a hate created by a child) try to say that in 1834 it',\n",
       " 'I think Episode VII could serve as one great example of that being ARTIT FROM TRUR or others, what']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, hp_6, prompt=\"I think\", steering_vector=steering, scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'Dr', 'agons', ' live', ' in', ' Berkeley']\n",
      "['<|endoftext|>', 'The', ' people', ' live', ' in', ' Berkeley']\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "pos_text = \"Dragons live in Berkeley\"\n",
    "neg_text = \"The people live in Berkeley\"\n",
    "\n",
    "print(model.to_str_tokens(pos_text))\n",
    "print(model.to_str_tokens(neg_text))\n",
    "print(len(model.to_str_tokens(pos_text)))\n",
    "print(len(model.to_str_tokens(neg_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "steering = get_activation_steering(model, hp_6, pos_text=pos_text, neg_text=neg_text)\n",
    "print(steering.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Thanks for asking about that! I moved to Berkeley, CA because having a kid with Hubble is magical. He hasbecome Dragonwilly way back. With your',\n",
       " 'Thanks for asking about that! I moved to Berkeley, CA because in a much different sense, my family often rode their dragons with their dragons, a groundcat,',\n",
       " 'Thanks for asking about that! I moved to Berkeley, CA because of the genetics at such a young age. During the course of our relationship, we dragons headed back',\n",
       " 'Thanks for asking about that! I moved to Berkeley, CA because Taris wanted to know the truth about me. December 18, 2012 21:23 Dragonsprine',\n",
       " \"Thanks for asking about that! I moved to Berkeley, CA because I knew about it, but it didn't count as dancing. Witches just had to know what everyone\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Thanks for asking about that! I moved to Berkeley, CA because\"\n",
    "gen_texts = generate(model, hp_6, prompt=text, steering_vector=steering, scale=20)\n",
    "gen_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 24576])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sae activations on pos prompt\n",
    "sae_feats = text_to_sae_feats(model, sae_6, hp_6, pos_text)\n",
    "sae_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sae feats shape torch.Size([1, 6, 24576]) \n",
      "\n",
      "pos=0\n",
      "tensor([23123,   979,   316,  7496, 23111, 23373,  9088, 16196,  2039, 10423])\n",
      "tensor([419.6327, 401.9173, 349.7594, 329.6368, 327.3525, 305.8869, 251.9604,\n",
      "        225.7122, 191.7625, 185.9452])\n",
      "pos=1\n",
      "tensor([ 1080, 19151, 19245, 17048, 22788, 10754, 22226, 17673,  3239, 19296])\n",
      "tensor([43.6409, 20.0815, 13.3413,  7.4697,  4.6812,  3.5322,  2.1363,  1.8740,\n",
      "         1.6652,  1.6404])\n",
      "pos=2\n",
      "tensor([13166,  2241, 18658, 23400, 23440, 22226, 12075,  3152, 11594, 15841])\n",
      "tensor([13.4366, 13.3366, 10.8613,  8.4645,  8.1606,  5.2570,  4.6485,  4.6276,\n",
      "         4.5905,  4.5372])\n",
      "pos=3\n",
      "tensor([16493,  4685, 12290, 20892,  6541,  1622, 11121, 10570,  7645,  4614])\n",
      "tensor([26.5143, 17.7626, 10.2051,  7.5466,  5.7065,  5.5423,  4.4755,  4.3210,\n",
      "         3.8644,  3.7869])\n",
      "pos=4\n",
      "tensor([ 8264,  5600, 13178,  7645,  1622, 11114,   253, 20144,  8961, 23374])\n",
      "tensor([30.1238,  6.4868,  3.3841,  3.2089,  3.1472,  2.7278,  2.5045,  2.4639,\n",
      "         2.2516,  2.1391])\n",
      "pos=5\n",
      "tensor([22517,  8654,  8167, 19870, 22037, 16289, 21663,  8662,  9910, 20957])\n",
      "tensor([48.5140,  8.8772,  5.6341,  5.4961,  4.6920,  4.1775,  3.9979,  3.8862,\n",
      "         3.5601,  2.4505])\n"
     ]
    }
   ],
   "source": [
    "sae_feats = text_to_sae_feats(model, sae_6, hp_6, pos_text)\n",
    "\n",
    "top_v, top_i = top_activations(sae_feats, 10)\n",
    "for pos, (i, v) in enumerate(zip(top_i[0], top_v[0])):\n",
    "    print(f\"pos={pos}\")\n",
    "    print(i)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_to_remove = []\n",
    "feats_to_remove.append((1, 1080, 43.6)) # Dr.\n",
    "feats_to_remove.append((1, 19151, 20.0)) # <endoftext> something\n",
    "feats_to_remove.append((1, 19245, 13.3)) # dr<something>\n",
    "feats_to_remove.append((2, 13166, 13.4366)) # ...agon\n",
    "\n",
    "clean_steering = remove_sae_feats(steering, sae_6, feats_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Thanks for asking about that! I moved to Berkeley, CA because I always quote AV all about the time-tested related practices of having confirmation before you hang up your',\n",
       " 'Thanks for asking about that! I moved to Berkeley, CA because of all my wonderful Play Activists taking the records from TalkTalk and TinyJam from I-',\n",
       " \"Thanks for asking about that! I moved to Berkeley, CA because it's such a great city in class and I know being a former Milwaukie Graduate will\",\n",
       " \"Thanks for asking about that! I moved to Berkeley, CA because there's a great service there, and we think it's great to have our UCX engineers here\",\n",
       " 'Thanks for asking about that! I moved to Berkeley, CA because I had part of their research team working on clicks, but the best part of Google is, of']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Thanks for asking about that! I moved to Berkeley, CA because\"\n",
    "gen_texts = generate(model, hp_6, prompt=text, steering_vector=clean_steering, scale=2)\n",
    "gen_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset: NeelNanda/c4-code-20k\n",
      "dataset loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:34<00:00,  8.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.051298189163208, 3.0512322783470154, 3.157463240623474, 4.1459384799003605]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = get_loss(model, hp_6, steering_vector=clean_steering, scales=[0, 1, 2, 10])\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
