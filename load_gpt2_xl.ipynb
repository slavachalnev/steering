{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f804517b730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6439e3d45848b78dd5d2396a700195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de29d7745b3d4eff91cd76c38b2c57a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = HookedTransformer.from_pretrained('gpt2-xl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "from sae_lens.training.sparse_autoencoder import SparseAutoencoder\n",
    "from sae_lens.training.config import LanguageModelSAERunnerConfig\n",
    "\n",
    "hook_point = \"blocks.20.hook_resid_pre\"\n",
    "bs = 64\n",
    "\n",
    "cf = {\n",
    "  \"model_name\": \"gpt2-xl\",\n",
    "  \"hook_point\": \"blocks.20.hook_resid_pre\",\n",
    "  \"hook_point_layer\": 20,\n",
    "  \"hook_point_head_index\": None,\n",
    "  \"dataset_path\": \"Skylion007/openwebtext\",\n",
    "  \"is_dataset_tokenized\": False,\n",
    "  \"context_size\": 128,\n",
    "  \"use_cached_activations\": False,\n",
    "  \"cached_activations_path\": \"activations/Skylion007_openwebtext/gpt2-small/blocks.1.hook_resid_pre\",\n",
    "  \"d_in\": 1600,\n",
    "  \"n_batches_in_buffer\": bs,\n",
    "  \"total_training_tokens\": 300000000,\n",
    "  \"store_batch_size\": bs,\n",
    "  \"device\": device,\n",
    "  \"seed\": 42,\n",
    "  \"dtype\": \"torch.float16\",\n",
    "  \"b_dec_init_method\": \"geometric_median\",\n",
    "  \"expansion_factor\": 32,\n",
    "  \"from_pretrained_path\": None,\n",
    "  \"l1_coefficient\": 0.00008,\n",
    "  \"lr\": 0.0004,\n",
    "  \"lr_scheduler_name\": None,\n",
    "  \"lr_warm_up_steps\": 5000,\n",
    "  \"train_batch_size\": 4096,\n",
    "  \"use_ghost_grads\": False,\n",
    "  \"feature_sampling_window\": 1000,\n",
    "  \"feature_sampling_method\": None,\n",
    "  \"resample_batches\": 1028,\n",
    "  \"feature_reinit_scale\": 0.2,\n",
    "  \"dead_feature_window\": 5000,\n",
    "  \"dead_feature_estimation_method\": \"no_fire\",\n",
    "  \"dead_feature_threshold\": 1e-8,\n",
    "  \"log_to_wandb\": True,\n",
    "  \"wandb_project\": \"mats_sae_training_gpt2_small_resid_pre_5\",\n",
    "  \"wandb_entity\": None,\n",
    "  \"wandb_log_frequency\": 100,\n",
    "  \"n_checkpoints\": 10,\n",
    "  \"checkpoint_path\": \"checkpoints/mm179kd2\",\n",
    "  \"d_sae\": 1600*32,\n",
    "  \"tokens_per_buffer\": 128,\n",
    "  \"run_name\": \"24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08\"\n",
    "}\n",
    "config = cf\n",
    "var_names = LanguageModelSAERunnerConfig.__init__.__code__.co_varnames\n",
    "config = {k: v for k, v in config.items() if k in var_names}\n",
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    **config\n",
    ")\n",
    "sparse_autoencoder = SparseAutoencoder(cfg)\n",
    "sparse_autoencoder.to(device)\n",
    "sparse_autoencoder.cfg.device = device\n",
    "\n",
    "layer = cfg.hook_point_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "tensors = {}\n",
    "with safe_open(\"gpt2-20.safetensors\", framework=\"pt\") as f:\n",
    "    for k in f.keys():\n",
    "        tensors[k] = f.get_tensor(k).cuda()\n",
    "        # if k == \"b_enc\":\n",
    "        #     tensors[k] -= 0.18\n",
    "tensors[\"b_enc\"] += tensors[\"b_dec\"] @ tensors[\"W_enc\"]\n",
    "sparse_autoencoder.load_state_dict(tensors, strict=False)\n",
    "sparse_autoencoder.to(device)\n",
    "sparse_autoencoder.cfg.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_acts_at_pos(text, pos=-1, silent=True, prepend_bos=True, n_top=10):\n",
    "    logits, cache = model.run_with_cache(text, prepend_bos=prepend_bos)\n",
    "    if pos is None:\n",
    "        hidden_state = cache[hook_point][0, :, :]\n",
    "    else:\n",
    "        hidden_state = cache[hook_point][0, pos, :].unsqueeze(0)\n",
    "    feature_acts = sparse_autoencoder(hidden_state).feature_acts\n",
    "    feature_acts = feature_acts.mean(dim=0)\n",
    "    top_v, top_i = torch.topk(feature_acts, n_top)\n",
    "    return top_v, top_i\n",
    "\n",
    "top_acts_at_pos(\"Anger something something\", pos=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_acts_at_pos(\"Anger\", pos=-1) # [126, 20811, 4524 ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data = load_dataset(\"NeelNanda/c4-code-20k\", split=\"train\")\n",
    "# data = load_dataset(\"NeelNanda/pile-10k\", split=\"train\")\n",
    "\n",
    "# tokenized_data = tutils.tokenize_and_concatenate(data, model.tokenizer, max_length=128)\n",
    "# tokenized_data = tokenized_data.shuffle(42)\n",
    "# all_tokens = tokenized_data[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sae_lens.training.session_loader import LMSparseAutoencoderSessionloader\n",
    "import transformer_lens.loading_from_pretrained as tllfp\n",
    "loader = LMSparseAutoencoderSessionloader(sparse_autoencoder.cfg)\n",
    "_, _, activation_store = loader.load_sae_training_group_session()\n",
    "\n",
    "\n",
    "def get_tokens(\n",
    "    activation_store,\n",
    "    n_batches_to_sample_from: int = 2**13,\n",
    "    n_prompts_to_select: int = 4096 * 6,\n",
    "):\n",
    "    all_tokens_list = []\n",
    "    pbar = tqdm(range(n_batches_to_sample_from))\n",
    "    for _ in pbar:\n",
    "        batch_tokens = activation_store.get_batch_tokens()\n",
    "        batch_tokens = batch_tokens[torch.randperm(batch_tokens.shape[0])][\n",
    "            : batch_tokens.shape[0]\n",
    "        ]\n",
    "        all_tokens_list.append(batch_tokens)\n",
    "\n",
    "    all_tokens = torch.cat(all_tokens_list, dim=0)\n",
    "    all_tokens = all_tokens[torch.randperm(all_tokens.shape[0])]\n",
    "    return all_tokens[:n_prompts_to_select]\n",
    "\n",
    "\n",
    "all_tokens = get_tokens(activation_store)  # should take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay so 126 is the anger feature right? Wrong!\n",
    "# 126 activates on most text\n",
    "selected_feature = 126\n",
    "activation_count = 0\n",
    "total = 0\n",
    "for i in range(10):\n",
    "    logits, cache = model.run_with_cache(all_tokens[i])\n",
    "    hidden_state = cache[hook_point][0]\n",
    "    feature_acts = sparse_autoencoder(hidden_state).feature_acts # shape [128, n_features]\n",
    "    selected_acts = feature_acts[:, selected_feature]\n",
    "\n",
    "    activation_count += (selected_acts > 0).sum().item()\n",
    "    total += selected_acts.shape[0]\n",
    "\n",
    "print(activation_count/total)\n",
    "# this feature activates on 99% of all tokens!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_vis.data_config_classes import SaeVisConfig\n",
    "from sae_vis.data_storing_fns import SaeVisData\n",
    "\n",
    "test_feature_idx_gpt = [126, 20811, 409]\n",
    "\n",
    "feature_vis_config_gpt = SaeVisConfig(\n",
    "    hook_point=hook_point,\n",
    "    features=test_feature_idx_gpt,\n",
    "    batch_size=bs,\n",
    "    minibatch_size_tokens=128,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    sae_vis_data_gpt = SaeVisData.create(\n",
    "        encoder=sparse_autoencoder,\n",
    "        model=model,\n",
    "        tokens=all_tokens,  # type: ignore\n",
    "        cfg=feature_vis_config_gpt,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "vis_dir = \"feature_vis\"\n",
    "if not os.path.exists(vis_dir):\n",
    "    os.makedirs(vis_dir)\n",
    "\n",
    "for idx, feature in enumerate(test_feature_idx_gpt):\n",
    "    if sae_vis_data_gpt.feature_stats.max[idx] == 0:\n",
    "        continue\n",
    "    filename = os.path.join(vis_dir, f\"{feature}_feature_vis.html\")\n",
    "    sae_vis_data_gpt.save_feature_centric_vis(filename, feature)\n",
    "    display(FileLink(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_acts_at_pos(\" any text you like!\", pos=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also, another crazy thing about this SAE:\n",
    "# the 0th token causes some features to activate with crazy high magnitude\n",
    "top_acts_at_pos(\" hello\", pos=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing with and without BOS\n",
    "top_acts_at_pos(\" hello\", pos=0, prepend_bos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my takeaway is this is a bad SAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that you can indeed find a reasonable \"Angry\" feature.\n",
    "# get features for angry, remove features which also activate on \"Calm\"\n",
    "\n",
    "angry_vals, angry_ids = top_acts_at_pos(\"Anger\", pos=-1, n_top=100)\n",
    "calm_vals, calm_ids = top_acts_at_pos(\"Calm\", pos=None, n_top=200)\n",
    "\n",
    "angry_vals = [t.item() for t in angry_vals]\n",
    "angry_ids = [t.item() for t in angry_ids]\n",
    "calm_vals = [t.item() for t in calm_vals]\n",
    "calm_ids = [t.item() for t in calm_ids]\n",
    "\n",
    "angry = zip(angry_vals, angry_ids)\n",
    "calm = zip(calm_vals, calm_ids)\n",
    "\n",
    "# remove zero-valued calm ids\n",
    "calm = [(v, i) for v, i in calm if v > 0]\n",
    "calm_set = set([i for v, i in calm])\n",
    "\n",
    "# remove calm ids from angry\n",
    "angry = [(v, i) for v, i in angry if i not in calm_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_idx_gpt = [20811, 4364, 33085]\n",
    "\n",
    "feature_vis_config_gpt = SaeVisConfig(\n",
    "    hook_point=hook_point,\n",
    "    features=test_feature_idx_gpt,\n",
    "    batch_size=bs,\n",
    "    minibatch_size_tokens=128,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    sae_vis_data_gpt = SaeVisData.create(\n",
    "        encoder=sparse_autoencoder,\n",
    "        model=model,\n",
    "        tokens=all_tokens,  # type: ignore\n",
    "        cfg=feature_vis_config_gpt,\n",
    "    )\n",
    "\n",
    "for idx, feature in enumerate(test_feature_idx_gpt):\n",
    "    if sae_vis_data_gpt.feature_stats.max[idx] == 0:\n",
    "        continue\n",
    "    filename = os.path.join(vis_dir, f\"{feature}_feature_vis.html\")\n",
    "    sae_vis_data_gpt.save_feature_centric_vis(filename, feature)\n",
    "    display(FileLink(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20811 # angry/sad/irritated feature\n",
    "# 4364 activates on words that end in \"er\" or \"ner\"\n",
    "# 33085 violence/aggression feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
