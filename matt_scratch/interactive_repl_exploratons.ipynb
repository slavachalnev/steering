{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1507c3790>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "\n",
    "from sae_lens import SparseAutoencoder\n",
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "\n",
    "# from steering.eval_utils import evaluate_completions\n",
    "from steering.utils import get_activation_steering, get_sae_diff_steering, remove_sae_feats, text_to_sae_feats, top_activations\n",
    "from steering.patch import generate, get_loss\n",
    "\n",
    "from steering.visualization import Table\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "def get_next_logits(\n",
    "    model: HookedTransformer,\n",
    "    fwd_hooks,\n",
    "    prompt=\"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    logits = model.run_with_hooks(prompt, fwd_hooks=fwd_hooks, prepend_bos=True)\n",
    "    print(logits.shape)\n",
    "    print(logits[0, -1, 255])\n",
    "    top_logits = logits[0, -1].topk(20)\n",
    "    # tokens = model.tokenizer.batch_decode(top_logits.indices)\n",
    "    # values = top_logits.values.tolist()\n",
    "\n",
    "    return top_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 50257])\n",
      "tensor(-6.2251)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([12.8311, 12.0995, 11.9779, 11.8784, 11.5975, 11.3170, 11.1910, 10.8977,\n",
       "        10.6984, 10.3434, 10.3292, 10.1011, 10.0181,  9.8481,  9.7113,  9.6436,\n",
       "         9.6348,  9.6215,  9.5249,  9.4524]),\n",
       "indices=tensor([ 262,  612,  257,  314,  618,  340,  356,  287,  345,  428,  661,  281,\n",
       "         616, 5384, 1466,  355,  477,  530,  611, 5519]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_logits(model, [], \"Once upon a time,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ny/hc9c812905l118ss_x5j9x380000gn/T/ipykernel_23050/2792573258.py:68: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  input_box.on_submit(on_submit)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac886d656be49d98cafd62465731236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Next step:', layout=Layout(margin='10px 0', width='100%'), placeholder='Enter a lo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb2328bce8a48f6b15b5721943bf299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid lightgrey', border_left='1px solid lightgrey', border_right='1px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad9bd1d81834756a50395c9308f53a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(border_bottom='1px solid lightgrey', border_left='1px solid lightgrey', bo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def generate_step_by_step(model: HookedTransformer, prompt: str, watch_tokens: list = []):\n",
    "    \"\"\"\n",
    "    Generate a REPL for the model.\n",
    "    \"\"\" \n",
    "    prompt_display = widgets.HTML(\n",
    "        value=f\"<b>Prompt:</b> {prompt}\",\n",
    "        placeholder='',\n",
    "        description='',\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "    input_box = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Enter a logit number to intervene or leave blank.',\n",
    "        description='Next step:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='100%', margin='10px 0')\n",
    "    )\n",
    "\n",
    "    output_prompt = widgets.Output(layout={'border': '1px solid lightgrey'})\n",
    "    output_area_left = widgets.Output(layout={'border': '1px solid lightgrey', 'width': '50%'})\n",
    "    output_area_right = widgets.Output(layout={'border': '1px solid lightgrey', 'width': '50%'})\n",
    "    side_by_side_output = widgets.HBox([output_area_left, output_area_right])\n",
    "\n",
    "    def execute_command(logits, model, watch_tokens=[]):\n",
    "        tokens = model.tokenizer.batch_decode(logits.indices)\n",
    "        values = logits.values.tolist()\n",
    "\n",
    "        with output_prompt:\n",
    "            clear_output(wait=True)\n",
    "            display(prompt_display)\n",
    "\n",
    "        with output_area_left:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            top_tokens = tokens[:20]\n",
    "            top_values = values[:20]\n",
    "            positions: list = list(range(1, 21))\n",
    "            try:\n",
    "                Table(\"Top Tokens\", [\"Positions\", \"Token\", \"Prob\"] , zip(positions, top_tokens, top_values))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "        with output_area_right:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "\n",
    "            top_tokens = tokens[:20]\n",
    "            top_values = values[:20]\n",
    "            positions: list = list(range(1, 21))\n",
    "            try:\n",
    "                Table(\"Other Tokens\", [\"Token\", \"Prob\"] , zip(top_tokens, top_values))\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    def on_submit(change):\n",
    "        logits = get_next_logits(model, [], prompt)\n",
    "        execute_command(logits, model, watch_tokens)\n",
    "\n",
    "        input_box.value = ''\n",
    "        input_box.focus = True\n",
    "\n",
    "    input_box.on_submit(on_submit)\n",
    "\n",
    "    display(input_box)\n",
    "    display(output_prompt)\n",
    "    display(side_by_side_output)\n",
    "\n",
    "    # display_output()\n",
    "\n",
    "    # execute_command(\"\")\n",
    "    # Initial display\n",
    "    logits = get_next_logits(model, [], prompt)\n",
    "    execute_command(logits, model, watch_tokens)\n",
    "\n",
    "# Run the REPL\n",
    "generate_step_by_step(model, \"Once upon a time, there were\", [555, 222])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = get_next_logits(model, [], \"The cat sat on the mat.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([ 17.2598,  16.8689,  16.6076,  ..., -19.3946, -20.7319, -20.7520]),\n",
       "indices=tensor([  198,   383,   632,  ..., 11039, 13945, 19476]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' The',\n",
       " ' It',\n",
       " ' He',\n",
       " ' She',\n",
       " ' His',\n",
       " ' \"',\n",
       " ' Her',\n",
       " ' I',\n",
       " ' A',\n",
       " ' Its',\n",
       " ' In',\n",
       " ' And',\n",
       " '\\n\\n',\n",
       " ' There',\n",
       " ' As',\n",
       " ' When',\n",
       " ' This',\n",
       " ' That',\n",
       " ' On',\n",
       " ' No',\n",
       " ' Then',\n",
       " ' With',\n",
       " ' My',\n",
       " ' One',\n",
       " ' An',\n",
       " ' But',\n",
       " ' After',\n",
       " ' At',\n",
       " ' Not',\n",
       " ' They',\n",
       " ' If',\n",
       " ' For',\n",
       " '<|endoftext|>',\n",
       " ' We',\n",
       " ' What',\n",
       " ' You',\n",
       " ' Two',\n",
       " ' (',\n",
       " ' To',\n",
       " ' Even',\n",
       " ' L',\n",
       " ' Just',\n",
       " ' All',\n",
       " ' Like',\n",
       " ' Now',\n",
       " ' How',\n",
       " ' From',\n",
       " \" '\",\n",
       " ' Harry',\n",
       " ' So',\n",
       " ' While',\n",
       " ' Ruby',\n",
       " ' Before',\n",
       " ' Behind',\n",
       " ' Every',\n",
       " ' T',\n",
       " ' Suddenly',\n",
       " ' Inside',\n",
       " ' Was',\n",
       " ' Looking',\n",
       " ' Some',\n",
       " ' W',\n",
       " ' Another',\n",
       " ' C',\n",
       " ' Once',\n",
       " ' Although',\n",
       " ' F',\n",
       " ' P',\n",
       " ' Nothing',\n",
       " ' Sitting',\n",
       " ' Why',\n",
       " ' S',\n",
       " ' Both',\n",
       " ' Only',\n",
       " ' Each',\n",
       " ' Or',\n",
       " ' Despite',\n",
       " ' R',\n",
       " ' Three',\n",
       " ' Slowly',\n",
       " ' By',\n",
       " ' Something',\n",
       " ' Maybe',\n",
       " ' Standing',\n",
       " ' Well',\n",
       " ' J',\n",
       " ' M',\n",
       " ' Had',\n",
       " ' Don',\n",
       " ' Though',\n",
       " ' H',\n",
       " ' Over',\n",
       " ' Sh',\n",
       " ' Blake',\n",
       " ' St',\n",
       " ' D',\n",
       " '\\xa0',\n",
       " ' Yang',\n",
       " ' Someone',\n",
       " ' Cat',\n",
       " ' Without',\n",
       " ' Yes',\n",
       " ' Y',\n",
       " ' B',\n",
       " ' Everyone',\n",
       " ' Of',\n",
       " ' Finally',\n",
       " ' Oh',\n",
       " ' Perhaps',\n",
       " ' Next',\n",
       " ' G',\n",
       " ' Did',\n",
       " ' N',\n",
       " ' E',\n",
       " ' Sc',\n",
       " ' K',\n",
       " ' Because',\n",
       " ' Eyes',\n",
       " ' Within',\n",
       " ' Right',\n",
       " ' Here',\n",
       " ' Since',\n",
       " ' Blood',\n",
       " ' Long',\n",
       " ' Black',\n",
       " ' Their',\n",
       " ' Mr',\n",
       " ' ',\n",
       " ' Jack',\n",
       " ' Under',\n",
       " ' Mom',\n",
       " ' Nick',\n",
       " ' First',\n",
       " ' Still',\n",
       " ' Me',\n",
       " ' Alice',\n",
       " ' Let',\n",
       " ' O',\n",
       " ' Sometimes',\n",
       " ' Seeing',\n",
       " ' Blue',\n",
       " ' Out',\n",
       " ' Your',\n",
       " ' Neither',\n",
       " ' John',\n",
       " ' Who',\n",
       " ' Through',\n",
       " ' Soon',\n",
       " ' Is',\n",
       " ' Le',\n",
       " ' None',\n",
       " ' Sun',\n",
       " ' Weiss',\n",
       " ' Instead',\n",
       " ' Everything',\n",
       " ' Alex',\n",
       " ' Ch',\n",
       " ' Lily',\n",
       " ' the',\n",
       " ' Un',\n",
       " ' Across',\n",
       " ' Four',\n",
       " ' Could',\n",
       " ' Would',\n",
       " ' Up',\n",
       " ' Several',\n",
       " ' Sw',\n",
       " ' Watching',\n",
       " ' Other',\n",
       " ' Our',\n",
       " ' People',\n",
       " ' However',\n",
       " ' Dr',\n",
       " ' Anna',\n",
       " ' Almost',\n",
       " ' James',\n",
       " ' Sl',\n",
       " ' Where',\n",
       " ' Judy',\n",
       " ' Cats',\n",
       " ' -',\n",
       " ' Th',\n",
       " ' These',\n",
       " ' More',\n",
       " ' Around',\n",
       " ' Red',\n",
       " ' Those',\n",
       " ' Bes',\n",
       " ' Unlike',\n",
       " ' Amy',\n",
       " ' Look',\n",
       " ' Most',\n",
       " ' Mrs',\n",
       " ' Yet',\n",
       " ' Too',\n",
       " ' Se',\n",
       " ' Re',\n",
       " ' Nobody',\n",
       " ' Jaune',\n",
       " ' Tim',\n",
       " ' Tears',\n",
       " ' Upon',\n",
       " ' Little',\n",
       " ' [',\n",
       " ' Sure',\n",
       " ' Al',\n",
       " ' Z',\n",
       " ' Never',\n",
       " ' Ginny',\n",
       " ' Elsa',\n",
       " ' Apparently',\n",
       " ' Hermione',\n",
       " ' Pull',\n",
       " ' Gr',\n",
       " ' Ra',\n",
       " ' Probably',\n",
       " ' Can',\n",
       " ' Half',\n",
       " ' Che',\n",
       " ' Immediately',\n",
       " ' Fl',\n",
       " ' Tom',\n",
       " ' Between',\n",
       " ' Very',\n",
       " ' Bl',\n",
       " ' Which',\n",
       " ' Today',\n",
       " ' Mark',\n",
       " ' Thinking',\n",
       " ' Ron',\n",
       " ' V',\n",
       " ' Pet',\n",
       " ' During',\n",
       " ' Somehow',\n",
       " ' Taking',\n",
       " ' Bob',\n",
       " ' Man',\n",
       " ' Head',\n",
       " ' Again',\n",
       " ' Normally',\n",
       " ' Mary',\n",
       " ' Max',\n",
       " '...',\n",
       " ' Charlie',\n",
       " ' Photo',\n",
       " ' Quiet',\n",
       " ' Any',\n",
       " ' Back',\n",
       " ' White',\n",
       " ' Outside',\n",
       " ' Mike',\n",
       " ' Big',\n",
       " ' Dark',\n",
       " ' Mother',\n",
       " ' Walking',\n",
       " ' Pyrrha',\n",
       " ' About',\n",
       " ' *',\n",
       " ' U',\n",
       " ' Ms',\n",
       " ' Sm',\n",
       " ' Cl',\n",
       " '.',\n",
       " ' Peter',\n",
       " ' Whatever',\n",
       " ' Angela',\n",
       " ' Emily',\n",
       " ' Hands',\n",
       " ' Should',\n",
       " ' David',\n",
       " ' Be',\n",
       " ' Sp',\n",
       " ' Adam',\n",
       " ' Am',\n",
       " ' Waiting',\n",
       " ' Ever',\n",
       " ' Soft',\n",
       " ' Uncle',\n",
       " ' Ten',\n",
       " ' Professor',\n",
       " ' Pl',\n",
       " ' Inst',\n",
       " ' Dogs',\n",
       " ' Being',\n",
       " ' According',\n",
       " ' Having',\n",
       " ' Lady',\n",
       " ' Quick',\n",
       " ' Hus',\n",
       " ' Bill',\n",
       " ' Sam',\n",
       " ' Sarah',\n",
       " ' Ar',\n",
       " ' Do',\n",
       " ' Moving',\n",
       " ' Many',\n",
       " 'The',\n",
       " ' Small',\n",
       " ' Chris',\n",
       " ' Six',\n",
       " ' Wolf',\n",
       " ' Ben',\n",
       " ' Gl',\n",
       " ' Holding',\n",
       " ' Good',\n",
       " ' Swe',\n",
       " ' Row',\n",
       " ' Curious',\n",
       " ' Water',\n",
       " ' Matt',\n",
       " ' Nora',\n",
       " ' Ad',\n",
       " ' Star',\n",
       " ' New',\n",
       " ' Brian',\n",
       " ' Care',\n",
       " ' Dog',\n",
       " ' Until',\n",
       " ' Down',\n",
       " ' Squ',\n",
       " ' \\xa0',\n",
       " ' Below',\n",
       " ' Fear',\n",
       " ' Aw',\n",
       " ' Lisa',\n",
       " ' Robin',\n",
       " ' Lo',\n",
       " ' Nine',\n",
       " ' Feeling',\n",
       " ' Lucy',\n",
       " ' Please',\n",
       " ' Shadow',\n",
       " ' Above',\n",
       " ' Rather',\n",
       " ' Five',\n",
       " ' Brown',\n",
       " ' Jason',\n",
       " ' Eventually',\n",
       " ' Rose',\n",
       " ' El',\n",
       " ' Will',\n",
       " ' Somewhere',\n",
       " ' Jenny',\n",
       " ' Molly',\n",
       " ' Po',\n",
       " ' Jon',\n",
       " ' X',\n",
       " ' Light',\n",
       " ' Er',\n",
       " ' Watch',\n",
       " ' Rub',\n",
       " ' Does',\n",
       " ' Katie',\n",
       " ' Whenever',\n",
       " ' Unfortunately',\n",
       " ' Fr',\n",
       " ' Cold',\n",
       " ' George',\n",
       " ' Paul',\n",
       " ' De',\n",
       " ' Hard',\n",
       " ' Mo',\n",
       " ' Sn',\n",
       " ' Breat',\n",
       " ' Dad',\n",
       " ' Were',\n",
       " ' Sweet',\n",
       " ' Br',\n",
       " ' Silence',\n",
       " ' Naruto',\n",
       " ' Arthur',\n",
       " ' Yeah',\n",
       " ' Jake',\n",
       " ' Wh',\n",
       " ' Said',\n",
       " ' Near',\n",
       " ' Clearly',\n",
       " ' Thank',\n",
       " ' Emma',\n",
       " ' Lee',\n",
       " ' Ye',\n",
       " ' Far',\n",
       " ' Last',\n",
       " ' Deep',\n",
       " ' Ann',\n",
       " ' Susan',\n",
       " ' Turning',\n",
       " ' and',\n",
       " ' Andy',\n",
       " ' Made',\n",
       " ' Kat',\n",
       " ' Always',\n",
       " ' Great',\n",
       " ' Michael',\n",
       " ' Joe',\n",
       " ' Draco',\n",
       " ' Dean',\n",
       " ' Chloe',\n",
       " ' Eight',\n",
       " ' Along',\n",
       " ' Didn',\n",
       " ' Ne',\n",
       " ' Tr',\n",
       " ' Wings',\n",
       " ' God',\n",
       " ' Meanwhile',\n",
       " ' Daniel',\n",
       " ' Mac',\n",
       " ' Luke',\n",
       " ' Luna',\n",
       " ' William',\n",
       " ' Claire',\n",
       " ' Karen',\n",
       " ' Heart',\n",
       " ' Ash',\n",
       " ' Danny',\n",
       " ' Yellow',\n",
       " ' Sirius',\n",
       " ' Master',\n",
       " ' Colin',\n",
       " ' Green',\n",
       " ' Men',\n",
       " ' Yu',\n",
       " ' Laura',\n",
       " ' Bare',\n",
       " ' Greg',\n",
       " ' Running',\n",
       " ' Looks',\n",
       " ' True',\n",
       " ' Father',\n",
       " ' Ah',\n",
       " ' Ro',\n",
       " ' Rem',\n",
       " ' Such',\n",
       " ' Ex',\n",
       " ' Jeff',\n",
       " ' Heather',\n",
       " ' Love',\n",
       " ' Usually',\n",
       " ' Think',\n",
       " ' Dragon',\n",
       " ' Wild',\n",
       " ' Pat',\n",
       " ' Bene',\n",
       " ' Bonnie',\n",
       " ' Actually',\n",
       " ' Car',\n",
       " ' Surely',\n",
       " ' Him',\n",
       " ' Claw',\n",
       " ' See',\n",
       " ' Old',\n",
       " ' Ma',\n",
       " ' Thomas',\n",
       " ' Dan',\n",
       " ' Hide',\n",
       " ' Dave',\n",
       " ' Really',\n",
       " ' Mar',\n",
       " ' Using',\n",
       " ' Julie',\n",
       " ' Wait',\n",
       " ' Seven',\n",
       " ' Miss',\n",
       " ' …',\n",
       " ' Click',\n",
       " ' Taylor',\n",
       " ' Women',\n",
       " ' Rachel',\n",
       " ' Later',\n",
       " ' Pupp',\n",
       " ' Trying',\n",
       " ' Young',\n",
       " ' Kitty',\n",
       " ' Jim',\n",
       " ' Pain',\n",
       " ' her',\n",
       " ' Beat',\n",
       " ' Cindy',\n",
       " ' Imagine',\n",
       " ' Hot',\n",
       " ' Thanks',\n",
       " ' Ke',\n",
       " ' Jamie',\n",
       " ' Kim',\n",
       " ' Sur',\n",
       " ' Take',\n",
       " ' Erin',\n",
       " ' Cut',\n",
       " ' Mat',\n",
       " ' Aunt',\n",
       " ' Steven',\n",
       " ' Snow',\n",
       " ' /',\n",
       " ' 2',\n",
       " ' Together',\n",
       " ' Warm',\n",
       " ' Picture',\n",
       " \" ''\",\n",
       " ' Off',\n",
       " ' Set',\n",
       " ' \"...',\n",
       " ' Patrick',\n",
       " ' Twice',\n",
       " ' Tall',\n",
       " ' Gu',\n",
       " ' Ren',\n",
       " ' Iris',\n",
       " ' Tiny',\n",
       " ' Han',\n",
       " ' Moments',\n",
       " ' Lil',\n",
       " ' Ow',\n",
       " ' Opening',\n",
       " ' Alone',\n",
       " ' Kn',\n",
       " ' Te',\n",
       " ' Years',\n",
       " ' Everybody',\n",
       " ' Tow',\n",
       " ' Luc',\n",
       " ' Hand',\n",
       " ' Fur',\n",
       " ' Del',\n",
       " ' Lin',\n",
       " ' Loud',\n",
       " ' Jo',\n",
       " ' En',\n",
       " ' Robert',\n",
       " ' Leo',\n",
       " ' Alan',\n",
       " ' Helen',\n",
       " ' Put',\n",
       " ' Already',\n",
       " ' Sk',\n",
       " ' Ky',\n",
       " ' Time',\n",
       " ' Pe',\n",
       " ' Jackie',\n",
       " ' Fred',\n",
       " ' Thought',\n",
       " ' Grab',\n",
       " ' Besides',\n",
       " ' Following',\n",
       " ' Baby',\n",
       " ' Beyond',\n",
       " ' Twenty',\n",
       " ' Audrey',\n",
       " ' Obviously',\n",
       " ' Large',\n",
       " ' Raven',\n",
       " ' Much',\n",
       " ' Fire',\n",
       " ' Cle',\n",
       " ' Perfect',\n",
       " ' Steve',\n",
       " ' Richard',\n",
       " ' Julia',\n",
       " ' Bella',\n",
       " ' Happy',\n",
       " ' Wra',\n",
       " ' Dust',\n",
       " ' Pretty',\n",
       " ' Marie',\n",
       " ' Left',\n",
       " ' Lena',\n",
       " ' �',\n",
       " ' Daddy',\n",
       " ' Dead',\n",
       " ' Joseph',\n",
       " ' he',\n",
       " ' Qu',\n",
       " ' —',\n",
       " ' Top',\n",
       " ' Lit',\n",
       " ' Em',\n",
       " ' Sit',\n",
       " ' Maggie',\n",
       " ' Q',\n",
       " ' Edward',\n",
       " ' Andrew',\n",
       " ' King',\n",
       " ' Co',\n",
       " ' Legs',\n",
       " ' Kevin',\n",
       " ' 1',\n",
       " ' Thick',\n",
       " ' Hor',\n",
       " ' Away',\n",
       " ' Marco',\n",
       " ' Cr',\n",
       " ' Ab',\n",
       " ' Ryan',\n",
       " ' Life',\n",
       " ' Conf',\n",
       " ' Larry',\n",
       " ' Luckily',\n",
       " ' Kate',\n",
       " ' she',\n",
       " ' Close',\n",
       " ' Occasionally',\n",
       " ' Given',\n",
       " ' Wang',\n",
       " ' Sil',\n",
       " ' Fuck',\n",
       " ' Ho',\n",
       " ' Mal',\n",
       " ' Bear',\n",
       " ' Whoever',\n",
       " ' Und',\n",
       " ' Anyone',\n",
       " ' Annie',\n",
       " ' Shortly',\n",
       " ' Fat',\n",
       " ' Originally',\n",
       " ' Henry',\n",
       " ' May',\n",
       " ' Mid',\n",
       " ' Fresh',\n",
       " ' Getting',\n",
       " ' Bright',\n",
       " ' Olivia',\n",
       " ' Har',\n",
       " ' App',\n",
       " ' Princess',\n",
       " ' Josh',\n",
       " ' Jesus',\n",
       " ' Part',\n",
       " ' Okay',\n",
       " ' Reading',\n",
       " ' Charles',\n",
       " ' Also',\n",
       " ' Jennifer',\n",
       " ' Hearing',\n",
       " ' Jill',\n",
       " ' Whether',\n",
       " ' –',\n",
       " ' Ran',\n",
       " ' Fox',\n",
       " ' Go',\n",
       " ' Ang',\n",
       " ' Li',\n",
       " ' Whis',\n",
       " ' Taken',\n",
       " ' Indeed',\n",
       " ' Super',\n",
       " ' Except',\n",
       " ' Amid',\n",
       " ' Putting',\n",
       " ' Has',\n",
       " ' Somebody',\n",
       " ' Pro',\n",
       " ' <',\n",
       " ' Nearly',\n",
       " ' Night',\n",
       " ' Magic',\n",
       " ' Have',\n",
       " ' Check',\n",
       " ' Wond',\n",
       " ' Mon',\n",
       " ' Among',\n",
       " ' Photograph',\n",
       " ' Hel',\n",
       " ' Knowing',\n",
       " ' Bell',\n",
       " ' Matthew',\n",
       " ' Damn',\n",
       " ' Asked',\n",
       " ' Sung',\n",
       " ' Frank',\n",
       " ' Penny',\n",
       " ' Grace',\n",
       " ' Elizabeth',\n",
       " ' Fif',\n",
       " ' Per',\n",
       " ' Att',\n",
       " ' Earlier',\n",
       " ' Sherlock',\n",
       " ' Ros',\n",
       " ' Hundreds',\n",
       " ' Teddy',\n",
       " ' Ted',\n",
       " ' Linda',\n",
       " ' Char',\n",
       " ' Silver',\n",
       " ' Pr',\n",
       " ' Hope',\n",
       " ' Meow',\n",
       " ' Tony',\n",
       " ' Remember',\n",
       " ' Jane',\n",
       " ' his',\n",
       " ' Op',\n",
       " ' Prince',\n",
       " ' Others',\n",
       " ' Lord',\n",
       " ' Are',\n",
       " ' Run',\n",
       " ' Johnny',\n",
       " ' Martin',\n",
       " ' Charlotte',\n",
       " ' Skin',\n",
       " ' Slightly',\n",
       " ' Laugh',\n",
       " ' Dozens',\n",
       " ' Surprisingly',\n",
       " ' Notice',\n",
       " ' 3',\n",
       " 'It',\n",
       " ' Willow',\n",
       " ' Lauren',\n",
       " ' Nor',\n",
       " ' Af',\n",
       " ' Friends',\n",
       " ' Open',\n",
       " ' Holly',\n",
       " ' Su',\n",
       " ' Rob',\n",
       " ' Beautiful',\n",
       " ' Fast',\n",
       " ' Eye',\n",
       " ' Viv',\n",
       " ' Jeremy',\n",
       " ' Bo',\n",
       " ' Imp',\n",
       " ' Int',\n",
       " ' Hannah',\n",
       " ' Food',\n",
       " ' \"…',\n",
       " ' Sus',\n",
       " ' Dawn',\n",
       " ' Literally',\n",
       " ' Words',\n",
       " ' Owner',\n",
       " ' Calm',\n",
       " ' Keep',\n",
       " ' Tw',\n",
       " ' Pre',\n",
       " ' Sir',\n",
       " ' Elena',\n",
       " ' Quite',\n",
       " ' Unable',\n",
       " ' Arms',\n",
       " ' Pure',\n",
       " ' Liu',\n",
       " ' Batman',\n",
       " ' Pink',\n",
       " ' Id',\n",
       " ' Justin',\n",
       " ' Initially',\n",
       " ' Scream',\n",
       " ' Scott',\n",
       " ' High',\n",
       " ' Jessie',\n",
       " ' Face',\n",
       " ' Hello',\n",
       " ' Amanda',\n",
       " ' 4',\n",
       " ' Sal',\n",
       " ' Get',\n",
       " ' Jessica',\n",
       " ' Angel',\n",
       " ' it',\n",
       " ' Tooth',\n",
       " ' Anne',\n",
       " ' Cait',\n",
       " ' Wendy',\n",
       " ' Holy',\n",
       " ' Tonight',\n",
       " ' Velvet',\n",
       " ' Pan',\n",
       " ' Az',\n",
       " ' Shit',\n",
       " ' Nin',\n",
       " ' Strange',\n",
       " ' Honestly',\n",
       " ' Debbie',\n",
       " ' Drawing',\n",
       " ' Abs',\n",
       " ' ~',\n",
       " ' Mia',\n",
       " ' Sch',\n",
       " ' Say',\n",
       " ' Natasha',\n",
       " ' Xander',\n",
       " ' Pete',\n",
       " ' Bruce',\n",
       " ' Hans',\n",
       " ' Mum',\n",
       " ' a',\n",
       " ' Female',\n",
       " ' Nicole',\n",
       " ' Ray',\n",
       " ' Definitely',\n",
       " ' Sere',\n",
       " 'He',\n",
       " ' Rod',\n",
       " ' Sand',\n",
       " ' Sens',\n",
       " ' Simon',\n",
       " ' Jay',\n",
       " ' Police',\n",
       " ' Huh',\n",
       " ' Spot',\n",
       " ' Children',\n",
       " ' Ev',\n",
       " ' Neville',\n",
       " ' Barbara',\n",
       " ' Cry',\n",
       " ' Sub',\n",
       " ' Mad',\n",
       " ' Keeping',\n",
       " ' Dudley',\n",
       " ' Empty',\n",
       " ' Fiona',\n",
       " ' $',\n",
       " ' Tor',\n",
       " ' Fer',\n",
       " ' Cathy',\n",
       " ' Captain',\n",
       " ' Ter',\n",
       " ' Bar',\n",
       " 'She',\n",
       " ' Press',\n",
       " ' Thirty',\n",
       " ' Poor',\n",
       " ' Call',\n",
       " ' Hers',\n",
       " ' Catherine',\n",
       " ' Rin',\n",
       " ' Donald',\n",
       " ' Chuck',\n",
       " ' Aside',\n",
       " ' Naturally',\n",
       " ' Bre',\n",
       " ' THE',\n",
       " ' Morgan',\n",
       " ' Queen',\n",
       " ' Male',\n",
       " ' Fle',\n",
       " ' Legend',\n",
       " ' Gone',\n",
       " ' Going',\n",
       " ' Darkness',\n",
       " '\\n\\xa0',\n",
       " ' #',\n",
       " ' Judging',\n",
       " ' Str',\n",
       " ' Wow',\n",
       " ' Eric',\n",
       " ' Drawn',\n",
       " ' Try',\n",
       " ' Hat',\n",
       " ' Low',\n",
       " ' Victoria',\n",
       " ' Son',\n",
       " ' Stephen',\n",
       " ' Sara',\n",
       " ' Fortunately',\n",
       " 'I',\n",
       " ' Buck',\n",
       " ' Du',\n",
       " ' Bull',\n",
       " ' Jean',\n",
       " ' Michelle',\n",
       " ' Tra',\n",
       " ' Thankfully',\n",
       " ' Kid',\n",
       " ' Clara',\n",
       " ' Cel',\n",
       " ' Seconds',\n",
       " ' Sleep',\n",
       " ' Maria',\n",
       " ' Sad',\n",
       " ' Human',\n",
       " ' Stars',\n",
       " ' Bur',\n",
       " ' Cur',\n",
       " ' Turn',\n",
       " ' Dro',\n",
       " ' Death',\n",
       " ' Power',\n",
       " ' Urs',\n",
       " ' 0',\n",
       " ' Fel',\n",
       " ' Daisy',\n",
       " ' Hair',\n",
       " ' Unsure',\n",
       " ' Bobby',\n",
       " ' Tang',\n",
       " ' Wood',\n",
       " ' Caroline',\n",
       " ' Mama',\n",
       " ' Against',\n",
       " ' Im',\n",
       " ' Rain',\n",
       " ' Gordon',\n",
       " ' Point',\n",
       " ' Tara',\n",
       " ' Wind',\n",
       " ' Lyn',\n",
       " ' Full',\n",
       " ' Guy',\n",
       " ' Owl',\n",
       " ' Billy',\n",
       " ' Sharp',\n",
       " ' Come',\n",
       " ' Kelly',\n",
       " ' Towards',\n",
       " ' Kay',\n",
       " ' Easy',\n",
       " ' Bat',\n",
       " ' Lu',\n",
       " ' Ign',\n",
       " ' Dumbledore',\n",
       " ' Neo',\n",
       " ' Slow',\n",
       " ' Second',\n",
       " ' Ey',\n",
       " ' Step',\n",
       " ' Into',\n",
       " ' Paw',\n",
       " ' Family',\n",
       " ' Tal',\n",
       " ' Sadly',\n",
       " ' Cam',\n",
       " ' Sakura',\n",
       " ' Janet',\n",
       " ' Mind',\n",
       " ' Rick',\n",
       " ' Lightning',\n",
       " ' Sounds',\n",
       " ' Severus',\n",
       " ' Con',\n",
       " ' Feet',\n",
       " ' Moon',\n",
       " ' Rel',\n",
       " ' Ginger',\n",
       " ' Move',\n",
       " ' Ian',\n",
       " ' Ed',\n",
       " ' Mil',\n",
       " ' Reg',\n",
       " ' Cynthia',\n",
       " ' Ste',\n",
       " ' Yuk',\n",
       " ' Read',\n",
       " ' Ag',\n",
       " ' Working',\n",
       " ' River',\n",
       " ' Ur',\n",
       " ' --',\n",
       " ' Melanie',\n",
       " ' Nat',\n",
       " 'A',\n",
       " ' Roger',\n",
       " ' Often',\n",
       " ' Child',\n",
       " ' Cou',\n",
       " ' Ry',\n",
       " ' Bab',\n",
       " ' Heavy',\n",
       " ' Snape',\n",
       " ' Ak',\n",
       " ' Ske',\n",
       " ' Louis',\n",
       " ' Smoke',\n",
       " ' Sen',\n",
       " ' Lucky',\n",
       " ' Rough',\n",
       " ' Mag',\n",
       " ' Free',\n",
       " ' Real',\n",
       " ' Bro',\n",
       " ' Boy',\n",
       " ' Bal',\n",
       " ' Summer',\n",
       " ' Des',\n",
       " ' Zhang',\n",
       " ' Meg',\n",
       " ' Same',\n",
       " ' Min',\n",
       " ' Ice',\n",
       " ' Leon',\n",
       " ' Par',\n",
       " ' Due',\n",
       " ' La',\n",
       " ' Nice',\n",
       " ' Short',\n",
       " ' Hillary',\n",
       " ' Hug',\n",
       " ' Mouth',\n",
       " ' Team',\n",
       " ' Sol',\n",
       " ' Sean',\n",
       " ' Polly',\n",
       " ' Lost',\n",
       " ' Feed',\n",
       " ' Kids',\n",
       " ...]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a4051 th {\n",
       "  background-color: #dddddd;\n",
       "  color: black;\n",
       "  text-align: center;\n",
       "  padding: 10px;\n",
       "  font-size: 16px;\n",
       "  border-bottom: 2px solid #ccc;\n",
       "}\n",
       "#T_a4051 td {\n",
       "  text-align: center;\n",
       "  padding: 8px;\n",
       "  font-size: 14px;\n",
       "  border-bottom: 1px solid #ccc;\n",
       "  color: black;\n",
       "}\n",
       "#T_a4051 tr:nth-child(odd) {\n",
       "  background-color: #f9f9f9;\n",
       "}\n",
       "#T_a4051 tr:nth-child(even) {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_a4051 table {\n",
       "  border-collapse: collapse;\n",
       "  width: 50%;\n",
       "  margin: 25px 0;\n",
       "  font-family: Arial, sans-serif;\n",
       "  border-radius: 8px;\n",
       "  overflow: hidden;\n",
       "}\n",
       "#T_a4051 caption {\n",
       "  caption-side: top;\n",
       "  font-size: 18px;\n",
       "  font-weight: bold;\n",
       "  margin-bottom: 10px;\n",
       "}\n",
       "#T_a4051 tbody tr:hover {\n",
       "  background-color: #e0e0e0;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a4051\">\n",
       "  <caption>Top Tokens</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a4051_level0_col0\" class=\"col_heading level0 col0\" >Positions</th>\n",
       "      <th id=\"T_a4051_level0_col1\" class=\"col_heading level0 col1\" >Token</th>\n",
       "      <th id=\"T_a4051_level0_col2\" class=\"col_heading level0 col2\" >Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a4051_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_a4051_row0_col1\" class=\"data row0 col1\" > to</td>\n",
       "      <td id=\"T_a4051_row0_col2\" class=\"data row0 col2\" >19.326347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a4051_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_a4051_row1_col1\" class=\"data row1 col1\" > you</td>\n",
       "      <td id=\"T_a4051_row1_col2\" class=\"data row1 col2\" >15.544235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a4051_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_a4051_row2_col1\" class=\"data row2 col1\" > a</td>\n",
       "      <td id=\"T_a4051_row2_col2\" class=\"data row2 col2\" >13.122031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a4051_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_a4051_row3_col1\" class=\"data row3 col1\" > the</td>\n",
       "      <td id=\"T_a4051_row3_col2\" class=\"data row3 col2\" >12.669929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a4051_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_a4051_row4_col1\" class=\"data row4 col1\" > everyone</td>\n",
       "      <td id=\"T_a4051_row4_col2\" class=\"data row4 col2\" >12.155163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a4051_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_a4051_row5_col1\" class=\"data row5 col1\" > my</td>\n",
       "      <td id=\"T_a4051_row5_col2\" class=\"data row5 col2\" >11.714208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a4051_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_a4051_row6_col1\" class=\"data row6 col1\" > people</td>\n",
       "      <td id=\"T_a4051_row6_col2\" class=\"data row6 col2\" >11.512468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_a4051_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_a4051_row7_col1\" class=\"data row7 col1\" > your</td>\n",
       "      <td id=\"T_a4051_row7_col2\" class=\"data row7 col2\" >11.403308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_a4051_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "      <td id=\"T_a4051_row8_col1\" class=\"data row8 col1\" > some</td>\n",
       "      <td id=\"T_a4051_row8_col2\" class=\"data row8 col2\" >11.295840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_a4051_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "      <td id=\"T_a4051_row9_col1\" class=\"data row9 col1\" > an</td>\n",
       "      <td id=\"T_a4051_row9_col2\" class=\"data row9 col2\" >11.197874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_a4051_row10_col0\" class=\"data row10 col0\" >11</td>\n",
       "      <td id=\"T_a4051_row10_col1\" class=\"data row10 col1\" >to</td>\n",
       "      <td id=\"T_a4051_row10_col2\" class=\"data row10 col2\" >11.063811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_a4051_row11_col0\" class=\"data row11 col0\" >12</td>\n",
       "      <td id=\"T_a4051_row11_col1\" class=\"data row11 col1\" > for</td>\n",
       "      <td id=\"T_a4051_row11_col2\" class=\"data row11 col2\" >10.855553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_a4051_row12_col0\" class=\"data row12 col0\" >13</td>\n",
       "      <td id=\"T_a4051_row12_col1\" class=\"data row12 col1\" > all</td>\n",
       "      <td id=\"T_a4051_row12_col2\" class=\"data row12 col2\" >10.786516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_a4051_row13_col0\" class=\"data row13 col0\" >14</td>\n",
       "      <td id=\"T_a4051_row13_col1\" class=\"data row13 col1\" > another</td>\n",
       "      <td id=\"T_a4051_row13_col2\" class=\"data row13 col2\" >10.624712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_a4051_row14_col0\" class=\"data row14 col0\" >15</td>\n",
       "      <td id=\"T_a4051_row14_col1\" class=\"data row14 col1\" > it</td>\n",
       "      <td id=\"T_a4051_row14_col2\" class=\"data row14 col2\" >10.610483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_a4051_row15_col0\" class=\"data row15 col0\" >16</td>\n",
       "      <td id=\"T_a4051_row15_col1\" class=\"data row15 col1\" > this</td>\n",
       "      <td id=\"T_a4051_row15_col2\" class=\"data row15 col2\" >10.489244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_a4051_row16_col0\" class=\"data row16 col0\" >17</td>\n",
       "      <td id=\"T_a4051_row16_col1\" class=\"data row16 col1\" >,</td>\n",
       "      <td id=\"T_a4051_row16_col2\" class=\"data row16 col2\" >10.448296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_a4051_row17_col0\" class=\"data row17 col0\" >18</td>\n",
       "      <td id=\"T_a4051_row17_col1\" class=\"data row17 col1\" > To</td>\n",
       "      <td id=\"T_a4051_row17_col2\" class=\"data row17 col2\" >10.444229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_a4051_row18_col0\" class=\"data row18 col0\" >19</td>\n",
       "      <td id=\"T_a4051_row18_col1\" class=\"data row18 col1\" > one</td>\n",
       "      <td id=\"T_a4051_row18_col2\" class=\"data row18 col2\" >10.359850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4051_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_a4051_row19_col0\" class=\"data row19 col0\" >20</td>\n",
       "      <td id=\"T_a4051_row19_col1\" class=\"data row19 col1\" > only</td>\n",
       "      <td id=\"T_a4051_row19_col2\" class=\"data row19 col2\" >10.359848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1529fd050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0d03f th {\n",
       "  background-color: #dddddd;\n",
       "  color: black;\n",
       "  text-align: center;\n",
       "  padding: 10px;\n",
       "  font-size: 16px;\n",
       "  border-bottom: 2px solid #ccc;\n",
       "}\n",
       "#T_0d03f td {\n",
       "  text-align: center;\n",
       "  padding: 8px;\n",
       "  font-size: 14px;\n",
       "  border-bottom: 1px solid #ccc;\n",
       "  color: black;\n",
       "}\n",
       "#T_0d03f tr:nth-child(odd) {\n",
       "  background-color: #f9f9f9;\n",
       "}\n",
       "#T_0d03f tr:nth-child(even) {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_0d03f table {\n",
       "  border-collapse: collapse;\n",
       "  width: 50%;\n",
       "  margin: 25px 0;\n",
       "  font-family: Arial, sans-serif;\n",
       "  border-radius: 8px;\n",
       "  overflow: hidden;\n",
       "}\n",
       "#T_0d03f caption {\n",
       "  caption-side: top;\n",
       "  font-size: 18px;\n",
       "  font-weight: bold;\n",
       "  margin-bottom: 10px;\n",
       "}\n",
       "#T_0d03f tbody tr:hover {\n",
       "  background-color: #e0e0e0;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0d03f\">\n",
       "  <caption>Watch Tokens</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0d03f_level0_col0\" class=\"col_heading level0 col0\" >Positions</th>\n",
       "      <th id=\"T_0d03f_level0_col1\" class=\"col_heading level0 col1\" >Token</th>\n",
       "      <th id=\"T_0d03f_level0_col2\" class=\"col_heading level0 col2\" >Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0d03f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0d03f_row0_col0\" class=\"data row0 col0\" >307</td>\n",
       "      <td id=\"T_0d03f_row0_col1\" class=\"data row0 col1\" > un</td>\n",
       "      <td id=\"T_0d03f_row0_col2\" class=\"data row0 col2\" >6.272503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d03f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0d03f_row1_col0\" class=\"data row1 col0\" >3261</td>\n",
       "      <td id=\"T_0d03f_row1_col1\" class=\"data row1 col1\" >less</td>\n",
       "      <td id=\"T_0d03f_row1_col2\" class=\"data row1 col2\" >3.372362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151ed4ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_indices(tensor, values):\n",
    "    \"\"\"\n",
    "    Get the indices of the given values in the tensor.\n",
    "\n",
    "    Args:\n",
    "    tensor (torch.Tensor): The tensor to search in.\n",
    "    values (list): The list of values to find in the tensor.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of indices where the values are found in the tensor.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for value in values:\n",
    "        idx = torch.nonzero(torch.eq(tensor, value)).squeeze()\n",
    "        if idx.numel() > 0:  # Check if there are any indices found\n",
    "            indices.append(idx.item())\n",
    "    return indices\n",
    "\n",
    "def preview_step(model: HookedTransformer, prompt: str, fwd_hooks=[], watch_logits: list = []):\n",
    "    logits = model.run_with_hooks(prompt, fwd_hooks=fwd_hooks, prepend_bos=True)\n",
    "\n",
    "    ranked_logits = logits[0, -1].topk(logits.shape[-1])\n",
    "    indices = ranked_logits.indices\n",
    "    values = ranked_logits.values\n",
    "\n",
    "    positions = list(range(1, 21))\n",
    "    top_values = [value.item() for value in values[0:20]]\n",
    "\n",
    "    top_indices = indices[0:20]\n",
    "    top_tokens = model.tokenizer.batch_decode(top_indices)\n",
    "    Table(\"Top Tokens\", [\"Positions\", \"Token\", \"Prob\"] , zip(positions, top_tokens, top_values))\n",
    "\n",
    "    if len(watch_logits) > 0:\n",
    "        watch_positions = get_indices(indices, watch_logits)\n",
    "        watch_values = [value.item() for value in values[watch_positions]]\n",
    "\n",
    "        watch_indices = indices[watch_positions]\n",
    "        watch_tokens = model.tokenizer.batch_decode(watch_indices)\n",
    "\n",
    "        Table(\"Watch Tokens\", [\"Positions\", \"Token\", \"Prob\"] , zip(watch_positions, watch_tokens, watch_values))\n",
    "\n",
    "\n",
    "preview_step(model, \"Today I want\", watch_logits=[555, 1203])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
