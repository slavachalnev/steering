{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x129a29890>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from jaxtyping import Float\n",
    "\n",
    "from sae_lens import SparseAutoencoder\n",
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "\n",
    "# from steering.eval_utils import evaluate_completions\n",
    "from steering.utils import get_activation_steering, get_sae_diff_steering, remove_sae_feats, text_to_sae_feats, top_activations\n",
    "from steering.preview import preview_next_step\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "hp_6 = tutils.get_act_name(\"resid_pre\", 6)\n",
    "sae_6 = get_gpt2_res_jb_saes(hp_6)[0][hp_6]\n",
    "sae_6 = sae_6.to(model.W_E.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[23123,   979,   316,  7496, 23111, 23373,  9088, 16196,  2039, 10423],\n",
      "         [23409, 19151,  4422,  6144, 21687, 11355, 13648,  1781, 21952,  1622],\n",
      "         [18490, 19117,  1622,  7574,   144, 21060, 15396,  1738, 14511, 19151],\n",
      "         [ 4003, 23672,  2312,  7574,  1622,   396, 14732, 15396, 19136, 24191],\n",
      "         [20985,  9995, 21393,  4492,  8120,  1738,  7574,  4512, 24191, 19136]]])\n",
      "tensor([32.6204, 12.4177, 12.2635,  8.3271,  6.1568,  6.1488,  5.6456,  4.6021,\n",
      "         3.0081,  2.9267])\n"
     ]
    }
   ],
   "source": [
    "sae_feats = text_to_sae_feats(model, sae_6, hp_6, \"I am so happy\")\n",
    "top_v, top_i = top_activations(sae_feats, 10)\n",
    "\n",
    "print(top_i)\n",
    "print(top_v[0,-1])\n",
    "\n",
    "# anger feature = (10131, 28.0792), 6415\n",
    "# happy feature = (20985, 32.62), (9995, 12.4177)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_position(\n",
    "    value: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    hook: HookPoint,\n",
    "    steering_vectors: Float[torch.Tensor, \"num d_model\"],\n",
    "    activations: Float[torch.Tensor, \"num\"],\n",
    "    c: float,\n",
    "    position: int\n",
    "    \n",
    ") -> Float[torch.Tensor, \"batch pos d_head\"]:\n",
    "    # add all feature_vectors to vector\n",
    "    for i, steering_vector in enumerate(steering_vectors):\n",
    "      value[:, position, :] += steering_vector * activations[i] * c\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [[20985, 32.62]]\n",
    "steering_vectors = [sae_6.W_dec[feature[0]] for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34191\n"
     ]
    }
   ],
   "source": [
    "vocab_index = model.tokenizer.encode(\"happy\")[0]\n",
    "print(vocab_index)\n",
    "\n",
    "# anger: 2564\n",
    "# happy: 34191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model: HookedTransformer, prompt: str, fwd_hooks=[], n_samples=5, max_length=20\n",
    "):\n",
    "    gen_texts = []\n",
    "    with model.hooks(fwd_hooks=fwd_hooks):\n",
    "        for _ in tqdm(range(n_samples)):\n",
    "            output = model.generate(prompt,\n",
    "                                    prepend_bos=True,\n",
    "                                    use_past_kv_cache=False,\n",
    "                                    max_new_tokens=max_length,\n",
    "                                    verbose=False,\n",
    "                                    )\n",
    "            gen_texts.append(output)\n",
    "    return gen_texts\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:14<00:00,  2.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I feel very ending with my students getting an education. They got education on legal access, started school brings them to',\n",
       " \"I feel very at ease. I'll eat mine\\n\\nand someday he'll be eating my cake or mixed with\",\n",
       " 'I feel very to be yelling that I am wearing the WWEwwkk from Wrestlemania XXII. Those WWE fans',\n",
       " 'I feel very and proud to have worked hard for a lifelong career in film and television development as a Sundance Centre',\n",
       " 'I feel very with one arm when I breastfeed and sound like a buzzing bear. To caregivers, my fetus looks']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook = (\n",
    "    hp_6,\n",
    "    partial(\n",
    "        patch_position, \n",
    "        steering_vectors=steering_vectors, \n",
    "        activations=[feature[1] for feature in features], \n",
    "        c=10,\n",
    "        position=3\n",
    "    )\n",
    ")\n",
    "\n",
    "fwd_hooks = [hook]\n",
    "prompt = \"I feel very\"\n",
    "\n",
    "generate(model, prompt, fwd_hooks=fwd_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e79da th {\n",
       "  background-color: #dddddd;\n",
       "  color: black;\n",
       "  text-align: center;\n",
       "  padding: 10px;\n",
       "  font-size: 16px;\n",
       "  border-bottom: 2px solid #ccc;\n",
       "}\n",
       "#T_e79da td {\n",
       "  text-align: center;\n",
       "  padding: 8px;\n",
       "  font-size: 14px;\n",
       "  border-bottom: 1px solid #ccc;\n",
       "  color: black;\n",
       "}\n",
       "#T_e79da tr:nth-child(odd) {\n",
       "  background-color: #f9f9f9;\n",
       "}\n",
       "#T_e79da tr:nth-child(even) {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_e79da table {\n",
       "  border-collapse: collapse;\n",
       "  width: 50%;\n",
       "  margin: 25px 0;\n",
       "  font-family: Arial, sans-serif;\n",
       "  border-radius: 8px;\n",
       "  overflow: hidden;\n",
       "}\n",
       "#T_e79da caption {\n",
       "  caption-side: top;\n",
       "  font-size: 18px;\n",
       "  font-weight: bold;\n",
       "  margin-bottom: 10px;\n",
       "}\n",
       "#T_e79da tbody tr:hover {\n",
       "  background-color: #e0e0e0;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e79da\">\n",
       "  <caption>Top Tokens</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_e79da_level0_col0\" class=\"col_heading level0 col0\" >Positions</th>\n",
       "      <th id=\"T_e79da_level0_col1\" class=\"col_heading level0 col1\" >Token</th>\n",
       "      <th id=\"T_e79da_level0_col2\" class=\"col_heading level0 col2\" >Act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_e79da_row0_col1\" class=\"data row0 col1\" > and</td>\n",
       "      <td id=\"T_e79da_row0_col2\" class=\"data row0 col2\" >16.932461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_e79da_row1_col1\" class=\"data row1 col1\" >,</td>\n",
       "      <td id=\"T_e79da_row1_col2\" class=\"data row1 col2\" >16.372375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_e79da_row2_col1\" class=\"data row2 col1\" > towards</td>\n",
       "      <td id=\"T_e79da_row2_col2\" class=\"data row2 col2\" >15.523688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_e79da_row3_col1\" class=\"data row3 col1\" > at</td>\n",
       "      <td id=\"T_e79da_row3_col2\" class=\"data row3 col2\" >15.224799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_e79da_row4_col1\" class=\"data row4 col1\" >ing</td>\n",
       "      <td id=\"T_e79da_row4_col2\" class=\"data row4 col2\" >15.043599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_e79da_row5_col1\" class=\"data row5 col1\" > toward</td>\n",
       "      <td id=\"T_e79da_row5_col2\" class=\"data row5 col2\" >14.765697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_e79da_row6_col1\" class=\"data row6 col1\" > directed</td>\n",
       "      <td id=\"T_e79da_row6_col2\" class=\"data row6 col2\" >13.932105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_e79da_row7_col1\" class=\"data row7 col1\" > or</td>\n",
       "      <td id=\"T_e79da_row7_col2\" class=\"data row7 col2\" >13.598452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "      <td id=\"T_e79da_row8_col1\" class=\"data row8 col1\" >ful</td>\n",
       "      <td id=\"T_e79da_row8_col2\" class=\"data row8 col2\" >13.591230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "      <td id=\"T_e79da_row9_col1\" class=\"data row9 col1\" >-</td>\n",
       "      <td id=\"T_e79da_row9_col2\" class=\"data row9 col2\" >13.402057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row10_col0\" class=\"data row10 col0\" >11</td>\n",
       "      <td id=\"T_e79da_row10_col1\" class=\"data row10 col1\" > that</td>\n",
       "      <td id=\"T_e79da_row10_col2\" class=\"data row10 col2\" >13.370094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row11_col0\" class=\"data row11 col0\" >12</td>\n",
       "      <td id=\"T_e79da_row11_col1\" class=\"data row11 col1\" >.</td>\n",
       "      <td id=\"T_e79da_row11_col2\" class=\"data row11 col2\" >13.345095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row12_col0\" class=\"data row12 col0\" >13</td>\n",
       "      <td id=\"T_e79da_row12_col1\" class=\"data row12 col1\" > in</td>\n",
       "      <td id=\"T_e79da_row12_col2\" class=\"data row12 col2\" >13.299267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row13_col0\" class=\"data row13 col0\" >14</td>\n",
       "      <td id=\"T_e79da_row13_col1\" class=\"data row13 col1\" > against</td>\n",
       "      <td id=\"T_e79da_row13_col2\" class=\"data row13 col2\" >13.278978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row14_col0\" class=\"data row14 col0\" >15</td>\n",
       "      <td id=\"T_e79da_row14_col1\" class=\"data row14 col1\" > over</td>\n",
       "      <td id=\"T_e79da_row14_col2\" class=\"data row14 col2\" >13.154414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row15_col0\" class=\"data row15 col0\" >16</td>\n",
       "      <td id=\"T_e79da_row15_col1\" class=\"data row15 col1\" > of</td>\n",
       "      <td id=\"T_e79da_row15_col2\" class=\"data row15 col2\" >12.975492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row16_col0\" class=\"data row16 col0\" >17</td>\n",
       "      <td id=\"T_e79da_row16_col1\" class=\"data row16 col1\" >)</td>\n",
       "      <td id=\"T_e79da_row16_col2\" class=\"data row16 col2\" >12.679031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row17_col0\" class=\"data row17 col0\" >18</td>\n",
       "      <td id=\"T_e79da_row17_col1\" class=\"data row17 col1\" > management</td>\n",
       "      <td id=\"T_e79da_row17_col2\" class=\"data row17 col2\" >12.646163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row18_col0\" class=\"data row18 col0\" >19</td>\n",
       "      <td id=\"T_e79da_row18_col1\" class=\"data row18 col1\" > is</td>\n",
       "      <td id=\"T_e79da_row18_col2\" class=\"data row18 col2\" >12.524611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e79da_row19_col0\" class=\"data row19 col0\" >20</td>\n",
       "      <td id=\"T_e79da_row19_col1\" class=\"data row19 col1\" > as</td>\n",
       "      <td id=\"T_e79da_row19_col2\" class=\"data row19 col2\" >12.472477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x129b5ebd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_87bcb th {\n",
       "  background-color: #dddddd;\n",
       "  color: black;\n",
       "  text-align: center;\n",
       "  padding: 10px;\n",
       "  font-size: 16px;\n",
       "  border-bottom: 2px solid #ccc;\n",
       "}\n",
       "#T_87bcb td {\n",
       "  text-align: center;\n",
       "  padding: 8px;\n",
       "  font-size: 14px;\n",
       "  border-bottom: 1px solid #ccc;\n",
       "  color: black;\n",
       "}\n",
       "#T_87bcb tr:nth-child(odd) {\n",
       "  background-color: #f9f9f9;\n",
       "}\n",
       "#T_87bcb tr:nth-child(even) {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_87bcb table {\n",
       "  border-collapse: collapse;\n",
       "  width: 50%;\n",
       "  margin: 25px 0;\n",
       "  font-family: Arial, sans-serif;\n",
       "  border-radius: 8px;\n",
       "  overflow: hidden;\n",
       "}\n",
       "#T_87bcb caption {\n",
       "  caption-side: top;\n",
       "  font-size: 18px;\n",
       "  font-weight: bold;\n",
       "  margin-bottom: 10px;\n",
       "}\n",
       "#T_87bcb tbody tr:hover {\n",
       "  background-color: #e0e0e0;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_87bcb\">\n",
       "  <caption>Watch Tokens</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_87bcb_level0_col0\" class=\"col_heading level0 col0\" >Positions</th>\n",
       "      <th id=\"T_87bcb_level0_col1\" class=\"col_heading level0 col1\" >Token</th>\n",
       "      <th id=\"T_87bcb_level0_col2\" class=\"col_heading level0 col2\" >Act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_87bcb_row0_col0\" class=\"data row0 col0\" >8877</td>\n",
       "      <td id=\"T_87bcb_row0_col1\" class=\"data row0 col1\" >anger</td>\n",
       "      <td id=\"T_87bcb_row0_col2\" class=\"data row0 col2\" >2.680283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1282ad790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_next_step(model, prompt, fwd_hooks=fwd_hooks, watch_logits=[2564, 34191])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
