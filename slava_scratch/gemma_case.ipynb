{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x31f3f50c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "\n",
    "from sae_lens import SparseAutoencoder\n",
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "from sae_lens import SparseAutoencoder, ActivationsStore\n",
    "\n",
    "from steering.eval_utils import evaluate_completions\n",
    "from steering.utils import get_activation_steering, get_sae_diff_steering, remove_sae_feats, text_to_sae_feats, top_activations\n",
    "from steering.patch import generate, get_loss\n",
    "\n",
    "from steering.utils import text_to_sae_feats, top_activations, normalise_decoder\n",
    "from steering.patch import generate\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slava/safety/steering/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80251d3496d343d0a9d9f68a9cc193c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(\"gemma-2b\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Ghost Grads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50efc234d8146ffa305da07689c3e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8a66ea559f4c6a89e6d329ec93c59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hp6 = \"blocks.6.hook_resid_post\"\n",
    "sae6 = SparseAutoencoder.from_pretrained(\"gemma-2b-res-jb\", hp6)\n",
    "normalise_decoder(sae6)\n",
    "activation_store = ActivationsStore.from_config(model, sae6.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2048])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_text = \"Anger\"\n",
    "neg_text = \"Calm\"\n",
    "\n",
    "anger_activation_steering= get_activation_steering(model, hp6, pos_text, neg_text)\n",
    "anger_activation_steering.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:17<00:00, 15.42s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I think that in some he had said her than he died!\\nI once mentioned the work of Jon Jones,',\n",
       " 'I think that if it weren’t for the war movie, the most interesting bit of the game, this game',\n",
       " 'I think that the roguish characters could use more distinct mechanics. Blades, Serpentina, Hylia, and',\n",
       " 'I think that app is shit, I actually hate how it goes like and, \"get this app, what about',\n",
       " 'I think that includes a lot of wisdom.\\nSunday Night Football, Gore and Munster seem back in form.\\n\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model,\n",
    "         hp6,\n",
    "         prompt=\"I think that\",\n",
    "         steering_vector=anger_activation_steering,\n",
    "         scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[24.4932, 23.9630, 23.2544, 21.0681, 20.9372, 20.6655, 20.3199,\n",
       "           19.8953, 19.0510, 18.4377],\n",
       "          [56.7609, 14.0818, 12.2185, 11.2966, 10.9838,  9.4307,  8.0595,\n",
       "            7.1658,  7.1005,  5.8064]]]),\n",
       " tensor([[[ 3390, 15881,  5347, 16334,   556,  8704, 11785,  5624,  5396,  6877],\n",
       "          [ 1062, 12753,  1213, 11968, 12167,  5915,  2491, 15173, 11912, 12312]]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_activations(text_to_sae_feats(model, sae6, hook_point=hp6, text=pos_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
