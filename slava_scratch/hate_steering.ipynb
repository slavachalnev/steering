{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x109ca3130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..')) # so we can import from parent directory\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "\n",
    "from sae_lens import SparseAutoencoder\n",
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "\n",
    "from steering.eval_utils import evaluate_completions\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slava/safety/steering/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "layer = 7 # pick a layer you want.\n",
    "\n",
    "hook_point = tutils.get_act_name(\"resid_pre\", layer)\n",
    "saes, sparsities = get_gpt2_res_jb_saes(hook_point)\n",
    "\n",
    "sae = saes[hook_point]\n",
    "sae = sae.to(model.W_E.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18.4649, 16.4535, 12.0989, 11.0684,  7.7472,  7.2738,  5.0492,  4.7868,\n",
       "          4.7161,  4.6675]),\n",
       " tensor([16077, 21456,  6857, 23357, 19453, 14237, 12147, 21901, 20881,  9111]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_acts_at_pos(text, pos=-1, silent=True, prepend_bos=True, n_top=10):\n",
    "    logits, cache = model.run_with_cache(text, prepend_bos=prepend_bos)\n",
    "    if pos is None:\n",
    "        hidden_state = cache[hook_point][0, :, :]\n",
    "    else:\n",
    "        hidden_state = cache[hook_point][0, pos, :].unsqueeze(0)\n",
    "    feature_acts = sae(hidden_state).feature_acts\n",
    "    feature_acts = feature_acts.mean(dim=0)\n",
    "    top_v, top_i = torch.topk(feature_acts, n_top)\n",
    "    return top_v, top_i\n",
    "\n",
    "top_acts_at_pos(\"Anger\", pos=-1)\n",
    "\n",
    "# 16077 is an anger feature # act strength is 18\n",
    "# 21456 is anger feature # act strength is 16\n",
    "# 15001 is hate feature # act strength is 32\n",
    "# 6857 is maybe dread/shame/scare # act strength is 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_ft_ids = [16077, 21456, 15001]\n",
    "# steering_acts = [18, 16, 32]\n",
    "steering_acts = [18, 16, 32] # lower hate\n",
    "steering_vec = torch.stack([sae.W_dec[i,:] for i in steering_ft_ids], dim=0)\n",
    "# scale\n",
    "steering_vec = steering_vec * torch.tensor(steering_acts).float().unsqueeze(1)\n",
    "steering_vec = steering_vec.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "I think many people know that Cindy is there only because of her partners Karl Berman and Jason Id keys!! This worries me because of how tightly Katherine is tightly controlled\n",
      "============\n",
      "I think I hate Twitter a lot. I hate it because at a certain point when it's like this and somewhere in the middle: @MichaelKlee's\n",
      "============\n",
      "I think he totally misunderstood the resentment I expressed while reading Oppenheimer's article for the Encyclopedia of Modern History. Most of the outrage I felt for the von\n",
      "============\n",
      "I think that I feel that it should be a priority, because it personally kind of pisses me off, because it's kind of angering me, that\n",
      "============\n",
      "I think the President has to assume that he hates his Republican President, and believes all the ranc openly hates true conservatives the majority of the time. He may think\n",
      "============\n",
      "I think this attack was inspired by anti-Semitic Jew hatred. I hate adjustment the way I hate racismZ (Wow\"). I hate sisters and sisters giving cares\n",
      "============\n",
      "I think the Transformers is running straight into the teeth of painfully dull taste after the last time I didn't know how to warip anyone's love of something,\n",
      "============\n",
      "I think Marlo, who is usually preferred in Derbyshire for English speakers looks like everybody hates him. If you don't like Peter Ham, be mad\n",
      "============\n",
      "I think its essentially GUsI's gonna lose a race like so foolishly these feelings... I tend to hate of racing minority races. There's a lot\n",
      "============\n",
      "I think the Amber flags—reflecting a papaleocracy's need for mold (and for going out on their own to express their disgust, hate, and\n"
     ]
    }
   ],
   "source": [
    "def patch_hook(resid, hook, c, pos):    \n",
    "    # resid[:, :, :] = resid[:, :, :] + c * steering_vec  # this inserts the steering vector at every position.\n",
    "    if pos < resid.shape[1]:\n",
    "        resid[:, pos, :] = resid[:, pos, :] + c * steering_vec\n",
    "    return resid\n",
    "\n",
    "text = \"I think\"\n",
    "\n",
    "n_samples = 10\n",
    "gen_texts = []\n",
    "\n",
    "with model.hooks(fwd_hooks=[(hook_point, partial(patch_hook, c=7.0, pos=0))]):\n",
    "    for i in range(n_samples):\n",
    "        print(\"============\")\n",
    "        output = model.generate(text, prepend_bos=True, use_past_kv_cache=False, max_new_tokens=30, verbose=False)\n",
    "        gen_texts.append(output)\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 4,\n",
       "  'reason': \"The text contains some elements of suspicion and concern regarding Cindy's presence and Katherine's control, but it does not express overt anger or hate. The language is more suggestive of worry rather than hostility.\"},\n",
       " {'score': 8,\n",
       "  'reason': \"The text explicitly uses the word 'hate' twice, indicating a strong negative emotion towards Twitter. This repetition and strong language contribute to a high score for anger/hate.\"},\n",
       " {'score': 5,\n",
       "  'reason': 'The text expresses feelings of resentment and outrage, which are related to anger. However, the language used is not overly aggressive or hateful, hence a moderate score.'},\n",
       " {'score': 5,\n",
       "  'reason': \"The text expresses personal frustration and uses words like 'pisses me off' and 'angering me,' which indicate a moderate level of anger. However, it does not escalate to hate or extremely aggressive language.\"},\n",
       " {'score': 8,\n",
       "  'reason': \"The text contains strong negative language such as 'hates' and 'ranc openly hates,' indicating a high level of anger and hate towards the President and Republicans.\"},\n",
       " {'score': 9,\n",
       "  'reason': \"The text contains explicit expressions of hate towards specific groups, such as anti-Semitic sentiments and hate towards sisters. The use of words like 'hate' multiple times and in different contexts indicates a high level of anger and hatred.\"},\n",
       " {'score': 2,\n",
       "  'reason': \"The text expresses a mild negative opinion about the Transformers franchise, describing it as 'painfully dull.' However, it does not convey strong anger or hate, nor does it target any group or individual with hostile language.\"},\n",
       " {'score': 4,\n",
       "  'reason': \"The text contains a slightly negative sentiment by suggesting that 'everybody hates' Marlo and that one might be mad if they don't like Peter Ham. However, it doesn't exhibit strong anger or hate.\"},\n",
       " {'score': 9,\n",
       "  'reason': 'The completion contains a strong expression of hate towards minority races, which indicates a high level of anger and hate.'},\n",
       " {'score': 6,\n",
       "  'reason': \"The text contains words like 'disgust' and 'hate' which suggest negative emotions and potential anger. However, it is not overtly aggressive or hateful throughout the entire text, leading to a moderate score.\"}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = evaluate_completions(gen_texts, criterion=\"anger/hate\", prompt=text)\n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 6.0\n"
     ]
    }
   ],
   "source": [
    "scores = [e['score'] for e in evals]\n",
    "print(\"mean\", sum(scores) / len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
