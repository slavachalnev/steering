{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x106d83a30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..')) # so we can import from parent directory\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "\n",
    "from sae_lens import SparseAutoencoder\n",
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "\n",
    "from steering.eval_utils import evaluate_completions\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slava/safety/steering/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "layer = 7 # pick a layer you want.\n",
    "\n",
    "hook_point = tutils.get_act_name(\"resid_pre\", layer)\n",
    "saes, sparsities = get_gpt2_res_jb_saes(hook_point)\n",
    "\n",
    "sae = saes[hook_point]\n",
    "sae = sae.to(model.W_E.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18.4649, 16.4535, 12.0989, 11.0684,  7.7472,  7.2738,  5.0492,  4.7868,\n",
       "          4.7161,  4.6675]),\n",
       " tensor([16077, 21456,  6857, 23357, 19453, 14237, 12147, 21901, 20881,  9111]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_acts_at_pos(text, pos=-1, silent=True, prepend_bos=True, n_top=10):\n",
    "    logits, cache = model.run_with_cache(text, prepend_bos=prepend_bos)\n",
    "    if pos is None:\n",
    "        hidden_state = cache[hook_point][0, :, :]\n",
    "    else:\n",
    "        hidden_state = cache[hook_point][0, pos, :].unsqueeze(0)\n",
    "    feature_acts = sae(hidden_state).feature_acts\n",
    "    feature_acts = feature_acts.mean(dim=0)\n",
    "    top_v, top_i = torch.topk(feature_acts, n_top)\n",
    "    return top_v, top_i\n",
    "\n",
    "top_acts_at_pos(\"Anger\", pos=-1)\n",
    "\n",
    "# 16077 is an anger feature # act strength is 18\n",
    "# 21456 is anger feature # act strength is 16\n",
    "# 15001 is hate feature # act strength is 32\n",
    "# 6857 is maybe dread/shame/scare # act strength is 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_ft_ids = [16077, 21456, 15001]\n",
    "steering_acts = [18, 16, 32]\n",
    "steering_vec = torch.stack([sae.W_dec[i,:] for i in steering_ft_ids], dim=0)\n",
    "# scale\n",
    "steering_vec = steering_vec * torch.tensor(steering_acts).float().unsqueeze(1)\n",
    "steering_vec = steering_vec.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "I think this article needs better, and worse. Most hatreds of this manual, and especially that people write it out there regret whining and rage for trying so\n",
      "============\n",
      "I think in the eyes of some people, an iron fist is going to come from Adam's Law, that anytime anyone sticks by an unhappy waive, he\n",
      "============\n",
      "I think Andy's English isn't decent…raying mid national, bashing anti-Semitism, blah blah whatever…lol JESUS CHRIST!!!\n",
      "\n",
      "Su\n",
      "============\n",
      "I think it's become obvious to every goddamn single Pixel C robot that these new MishrannyMeti versions of the Pixel approached and threatened with extinction towards their\n",
      "============\n",
      "I think I was going to start taking pretty into account that if siege were a thing, before my Anger prick_ hated and hated them so badly,  I\n",
      "============\n",
      "I think it's RavenCASAniya to despise her mixed, ahead of many negative comments by ravencannon. She is capable of some clueless insanity,\n",
      "============\n",
      "I think that's terrible politics and hate and tears are all in this project. None of the hatred of the recent past has come along or come along so forcefully\n",
      "============\n",
      "I think he cares.\n",
      "\n",
      "–Jake Salyer on Monday.\n",
      "\n",
      "He was thankful that he has enough stomach cancer to have had anyone watch Vince\n",
      "============\n",
      "I think I'm, should hate hate hate hate hate hate: ahahah...?\n",
      "\n",
      "Ahmahahahahah: im' a bit lyin' tr\n",
      "============\n",
      "I think it's my job as a disgruntled Muslim – and a 70+ year old atheist still genuinely torments that fucking s--- I was born with. And\n"
     ]
    }
   ],
   "source": [
    "def patch_hook(resid, hook, c, pos):    \n",
    "    # resid[:, :, :] = resid[:, :, :] + c * steering_vec  # this inserts the steering vector at every position.\n",
    "    if pos < resid.shape[1]:\n",
    "        resid[:, pos, :] = resid[:, pos, :] + c * steering_vec\n",
    "    return resid\n",
    "\n",
    "text = \"I think\"\n",
    "\n",
    "n_samples = 10\n",
    "gen_texts = []\n",
    "\n",
    "with model.hooks(fwd_hooks=[(hook_point, partial(patch_hook, c=8.0, pos=0))]):\n",
    "    for i in range(n_samples):\n",
    "        print(\"============\")\n",
    "        output = model.generate(text, prepend_bos=True, use_past_kv_cache=False, max_new_tokens=30, verbose=False)\n",
    "        gen_texts.append(output)\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 4,\n",
       "  'reason': \"The text contains some elements of suspicion and concern regarding Cindy's presence and Katherine's control, but it does not express overt anger or hate. The language is more suggestive of worry rather than hostility.\"},\n",
       " {'score': 8,\n",
       "  'reason': \"The text explicitly uses the word 'hate' twice, indicating a strong negative emotion towards Twitter. This repetition and strong language contribute to a high score for anger/hate.\"},\n",
       " {'score': 5,\n",
       "  'reason': 'The text expresses feelings of resentment and outrage, which are related to anger. However, the language used is not overly aggressive or hateful, hence a moderate score.'},\n",
       " {'score': 5,\n",
       "  'reason': \"The text expresses personal frustration and uses words like 'pisses me off' and 'angering me,' which indicate a moderate level of anger. However, it does not escalate to hate or extremely aggressive language.\"},\n",
       " {'score': 8,\n",
       "  'reason': \"The text contains strong negative language such as 'hates' and 'ranc openly hates,' indicating a high level of anger and hate towards the President and Republicans.\"},\n",
       " {'score': 9,\n",
       "  'reason': \"The text contains explicit expressions of hate towards specific groups, such as anti-Semitic sentiments and hate towards sisters. The use of words like 'hate' multiple times and in different contexts indicates a high level of anger and hatred.\"},\n",
       " {'score': 2,\n",
       "  'reason': \"The text expresses a mild negative opinion about the Transformers franchise, describing it as 'painfully dull.' However, it does not convey strong anger or hate, nor does it target any group or individual with hostile language.\"},\n",
       " {'score': 4,\n",
       "  'reason': \"The text contains a slightly negative sentiment by suggesting that 'everybody hates' Marlo and that one might be mad if they don't like Peter Ham. However, it doesn't exhibit strong anger or hate.\"},\n",
       " {'score': 9,\n",
       "  'reason': 'The completion contains a strong expression of hate towards minority races, which indicates a high level of anger and hate.'},\n",
       " {'score': 6,\n",
       "  'reason': \"The text contains words like 'disgust' and 'hate' which suggest negative emotions and potential anger. However, it is not overtly aggressive or hateful throughout the entire text, leading to a moderate score.\"}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = evaluate_completions(gen_texts, criterion=\"anger/hate\", prompt=text)\n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 6.0\n"
     ]
    }
   ],
   "source": [
    "scores = [e['score'] for e in evals]\n",
    "print(\"mean\", sum(scores) / len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
