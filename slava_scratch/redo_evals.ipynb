{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fa7241f41c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sae_lens import SparseAutoencoder\n",
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "from sae_lens import SparseAutoencoder, ActivationsStore\n",
    "\n",
    "from steering.eval_utils import evaluate_completions\n",
    "from steering.utils import text_to_sae_feats, top_activations, normalise_decoder, get_activation_steering\n",
    "from steering.patch import generate, get_scores_and_losses, patch_resid, get_loss, scores_2d\n",
    "\n",
    "from sae_vis.data_config_classes import SaeVisConfig\n",
    "from sae_vis.data_storing_fns import SaeVisData\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = ['Anger', 'London']\n",
    "save_dir = \"runs/fixed_anger_london\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('runs/fixed_anger_london/gen_log.json', 'r') as f:\n",
    "    gens = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['texts', 'scales', 'scores_1', 'scores_2', 'coherence_scores'])\n"
     ]
    }
   ],
   "source": [
    "print(gens[0].keys())\n",
    "scales = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1 = torch.zeros((len(scales), len(scales)))\n",
    "scores_2 = torch.zeros((len(scales), len(scales)))\n",
    "losses = torch.zeros((len(scales), len(scales)))\n",
    "coherence = torch.zeros((len(scales), len(scales)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:00<00:00, 7919.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for gen_dict in tqdm(gens):\n",
    "    s1, s2 = gen_dict['scales']\n",
    "    i = scales.index(s1)\n",
    "    j = scales.index(s2)\n",
    "    scores_1[i, j] = sum(gen_dict['scores_1'])/len(gen_dict['scores_1'])\n",
    "    scores_2[i, j] = sum(gen_dict['scores_2'])/len(gen_dict['scores_2'])\n",
    "    coherence[i, j] = sum(gen_dict['coherence_scores'])/len(gen_dict['coherence_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 15])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(scores_1, x=scales, y=scales,\n",
    "          title=f\"{feature_descriptions[0]} scores\",labels={'x': feature_descriptions[1], 'y': feature_descriptions[0]},\n",
    "          color_continuous_scale=\"RdBu\", color_continuous_midpoint=0)\n",
    "fig.write_html(f\"{save_dir}/scores_1.html\")\n",
    "fig.write_image(f\"{save_dir}/scores_1.png\")\n",
    "        \n",
    "fig = px.imshow(scores_2, x=scales, y=scales,\n",
    "            title=f\"{feature_descriptions[1]} scores\",labels={'x': feature_descriptions[1], 'y': feature_descriptions[0]},\n",
    "            color_continuous_scale=\"RdBu\", color_continuous_midpoint=0)\n",
    "fig.write_html(f\"{save_dir}/scores_2.html\")\n",
    "fig.write_image(f\"{save_dir}/scores_2.png\")\n",
    "\n",
    "fig = px.imshow(coherence, x=scales, y=scales,\n",
    "            title=\"Coherence scores\",labels={'x': feature_descriptions[1], 'y': feature_descriptions[0]},\n",
    "            color_continuous_scale=\"RdBu\", color_continuous_midpoint=0)\n",
    "fig.write_html(f\"{save_dir}/coherence_scores.html\")\n",
    "fig.write_image(f\"{save_dir}/coherence_scores.png\")\n",
    "\n",
    "# fig = px.imshow(losses, x=scales, y=scales,\n",
    "#             title=\"Losses\",labels={'x': feature_descriptions[1], 'y': feature_descriptions[0]},\n",
    "#             color_continuous_scale=\"RdBu\", color_continuous_midpoint=0)\n",
    "# fig.write_html(f\"{save_dir}/losses.html\")\n",
    "# fig.write_image(f\"{save_dir}/losses.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tensors\n",
    "torch.save(scores_1, f\"{save_dir}/scores_1.pt\")\n",
    "torch.save(scores_2, f\"{save_dir}/scores_2.pt\")\n",
    "torch.save(coherence, f\"{save_dir}/coherence_scores.pt\")\n",
    "torch.save(losses, f\"{save_dir}/losses.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
